{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# Display all rows and cols\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv('data/train.csv')\n",
    "test_dataset = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Store id from test dataset separately and drop it\n",
    "ID_TEST = test_dataset['id']\n",
    "test_dataset.drop('id', axis=1, inplace=True)\n",
    "\n",
    "# Drop id from train dataset\n",
    "train_dataset.drop('id', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "rows_train = train_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_dataset.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print train_dataset.shape\n",
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Skewness of dataset\n",
    "# Should be close to 0\n",
    "train_dataset.skew()\n",
    "\n",
    "# loss is most skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "numeric_data_train = train_dataset.select_dtypes(include=['float64'])\n",
    "numeric_cols = numeric_data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Violin plots for numeric attributes\n",
    "n_cols = 3\n",
    "n_rows = (len(numeric_cols) / n_cols) + (len(numeric_cols) % n_cols)\n",
    "\n",
    "for i in xrange(n_rows):\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=n_cols, figsize=(12, 6))\n",
    "    for j in xrange(n_cols):\n",
    "        sns.violinplot(y=numeric_cols[i*n_cols + j], data=numeric_data_train, ax=ax[j])\n",
    "        \n",
    "# loss is heavily skewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# skew correction\n",
    "train_dataset['loss'] = np.log1p(train_dataset['loss'])\n",
    "sns.violinplot(y='loss', data=train_dataset)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Drop 'loss' from continuous data\n",
    "numeric_data_train.drop('loss', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate pearson coefficient\n",
    "corr_train_data = numeric_data_train.corr()\n",
    "corr_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Correlation threshold\n",
    "corr_threshold = 0.5\n",
    "\n",
    "n_cont_features = len(corr_train_data.columns)\n",
    "\n",
    "high_corrs = []\n",
    "\n",
    "# Find features with correaltion more than or equal to the threshold\n",
    "for i in xrange(0, n_cont_features):\n",
    "    for j in xrange(i+1, n_cont_features):\n",
    "        corr = corr_train_data.iloc[i,j]\n",
    "        if abs(corr) >= corr_threshold:\n",
    "            high_corrs.append(((corr_train_data.columns[i], corr_train_data.columns[j]), corr))\n",
    "\n",
    "sorted_corrs = sorted(high_corrs, key=lambda x: -abs(x[1])) # -abs for descending order\n",
    "\n",
    "# correlations in descending order\n",
    "for corr in sorted_corrs:\n",
    "    print \"{} and {} -------> {:.3f}\".format(corr[0][0], corr[0][1], corr[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter plot of highly correlated feature pairs\n",
    "for pair, corr in sorted_corrs:\n",
    "    sns.pairplot(data=train_dataset, x_vars=pair[0], y_vars=pair[1], size=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "# Encode categorical variables\n",
    "labels = {} # holds list of unique categorical vars\n",
    "\n",
    "cat_cols = train_dataset.select_dtypes(include=['object']).columns\n",
    "\n",
    "for col in cat_cols:\n",
    "    # take unique cols from both train and test sets so that no variables are missed\n",
    "    unique_cat_train = train_dataset[col].unique()\n",
    "    unique_cat_test = test_dataset[col].unique()\n",
    "    labels[col] = (list(set(unique_cat_train) | set(unique_cat_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "all_dataset = train_dataset.append(test_dataset)\n",
    "all_dataset.drop('loss', axis=1, inplace=True)\n",
    "\n",
    "# Label encode\n",
    "all_dataset = pd.get_dummies(all_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "\n",
    "train = all_dataset.iloc[0: rows_train]\n",
    "test = all_dataset.iloc[rows_train:]\n",
    "\n",
    "# Split train dataset into train and cross-validation set\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(train, train_dataset['loss'], test_size=0.2, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_seed = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge(alpha=1.0, random_state=random_seed)\n",
    "ridge_model.fit(x_train, y_train)\n",
    "cv_result = ridge_model.predict(x_val)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
